# ç³»ç»Ÿæ¶æ„ï¼ˆå½“å‰å®ç°å®¡é˜…ç‰ˆï¼‰

æœ¬æ–‡æ¡£åŸºäºå½“å‰ä»£ç å®ç°ï¼ˆ`eval/` + `llm_core/`ï¼‰æ•´ç†ï¼Œä¸æ˜¯ç›®æ ‡æ€è®¾è®¡å›¾ã€‚

## 1. æ¶æ„æ€»è§ˆå›¾

```mermaid
flowchart TB
    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ·å¼å®šä¹‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    classDef input     fill:#EFF6FF,stroke:#3B82F6,stroke-width:2px,color:#1E3A5F,font-weight:bold
    classDef orch      fill:#F0FDF4,stroke:#22C55E,stroke-width:2px,color:#14532D,font-weight:bold
    classDef model     fill:#FFF7ED,stroke:#F97316,stroke-width:2px,color:#7C2D12,font-weight:bold
    classDef store     fill:#F5F3FF,stroke:#8B5CF6,stroke-width:2px,color:#3B0764,font-weight:bold
    classDef output    fill:#FFF1F2,stroke:#F43F5E,stroke-width:2px,color:#881337,font-weight:bold
    classDef task      fill:#ECFEFF,stroke:#06B6D4,stroke-width:2px,color:#164E63,font-weight:bold
    classDef api       fill:#FEFCE8,stroke:#EAB308,stroke-width:2px,color:#713F12,font-weight:bold

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¾“å…¥å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph INPUT["  ğŸ“¥ INPUT â€” è¾“å…¥å±‚  "]
        direction LR
        CLI["ğŸ–¥ï¸ CLI\npython -m eval.cli.runner"]
        DS["ğŸ“„ Dataset\n*.jsonl"]
        WF_YAML["ğŸ“‹ Workflow Spec\nnews_pipeline.yaml"]
        REG_YAML["âš™ï¸ Model Registry\nllm_providers.yaml"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç¼–æ’å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph ORCH["  ğŸ›ï¸ ORCHESTRATOR â€” ç¼–æ’å±‚ (eval/)  "]
        direction TB
        RUNNER["ğŸƒ Runner\nrunner.py\nå•ä»»åŠ¡ / workflow å…¥å£"]
        WFL["ğŸ”€ WorkflowLoader\nworkflow.py\nstep ä¾èµ– & input_from"]
        REG["ğŸ“¦ ModelRegistry\nregistry.py\næ¨¡å‹æ³¨å†Œ + æˆæœ¬ä¼°ç®—"]
        GATE["ğŸšª LLMGateway\ngateway.py\nç»Ÿä¸€è°ƒç”¨é—¨é¢"]
        CACHE["ğŸ’¾ EvalCache\ncache.py\nmodel+params+messages é”®"]
        MET["ğŸ“Š Metrics\nmetrics.py\naggregate_records()"]
        REP["ğŸ“ Reporter\nreporter.py\nMarkdownReporter"]

        subgraph TASKS["  ä»»åŠ¡æ’ä»¶å±‚ (eval/tasks/)  "]
            direction LR
            T_BASE["ğŸ”§ EvalTask\nbase.py\næŠ½è±¡åŸºç±»"]
            T_IE["ğŸ“Œ IEJsonTask\nie_json.py"]
            T_STOCK["ğŸ“ˆ StockScoreTask\nstock_score.py"]
            T_DEDUP["ğŸ—ï¸ NewsDedupTask\nnews_dedup.py"]
            T_GEN["âš¡ GenericTask\ngeneric.py"]
        end
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¨¡å‹å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph MODEL["  ğŸ¤– MODEL LAYER â€” æ¨¡å‹å±‚ (llm_core/)  "]
        direction TB
        CLIENT_F["ğŸ­ LLM Client Factory\nbase_client.py"]
        OAI["ğŸ”Œ OpenAICompatibleClient\nopenai_client.py"]
        PROMPT["âœï¸ PromptRenderer\nprompt_renderer.py\nJinja2 æ¸²æŸ“"]
        PARSER["ğŸ” ResponseParser\nresponse_parser.py"]
        BATCH["âš™ï¸ BatchHelper\nbatch.py"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å­˜å‚¨å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph STORE_L["  ğŸ—„ï¸ STORE â€” å­˜å‚¨å±‚ (eval/)  "]
        direction LR
        RSTORE["ğŸ“ RunStore\nstore.py\näº§ç‰©è¯»å†™æŠ½è±¡"]
        DATA_DIR["ğŸ“‚ runs/{timestamp}/"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤–éƒ¨ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph APIS["  ğŸŒ å¤–éƒ¨ LLM API  "]
        direction LR
        DEEPSEEK["DeepSeek\nAPI"]
        KIMI["Kimi\næœˆä¹‹æš—é¢"]
        GPT["OpenAI\ngpt-4o etc."]
        OTHERS["å…¶ä»–\nOpenAI-Compatible"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¾“å‡ºäº§ç‰© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph OUTPUT["  ğŸ“¤ OUTPUT â€” è¾“å‡ºäº§ç‰©  "]
        direction LR
        O_CFG["ğŸ“„ config.json\nè¿è¡Œé…ç½®å¿«ç…§"]
        O_RES["ğŸ“Š results.jsonl\né€æ¡ç»“æœ v1"]
        O_SUM["ğŸ“‹ summary.csv\nèšåˆç»Ÿè®¡ v1"]
        O_RPT["ğŸ“ report.md\nå¯è¯»æŠ¥å‘Š"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é…ç½®æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph CONFIGS["  ğŸ“ CONFIGS  "]
        direction LR
        C_PROV["llm_providers.yaml\n/json"]
        C_PROMPT["prompts/\n*.yaml"]
        C_ENV[".env\nAPI Keys"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®é›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph DATASETS["  ğŸ“‚ DATASETS  "]
        direction LR
        D_BENCH["benchmark_news\n.jsonl"]
        D_DEMO["demo_news\n.jsonl"]
        D_EVAL["news_summary_eval\n.jsonl"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¿æ¥å…³ç³» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    CLI --> RUNNER
    DS --> RUNNER
    WF_YAML --> WFL --> RUNNER
    REG_YAML --> REG

    RUNNER --> TASKS
    RUNNER --> GATE
    RUNNER --> MET
    RUNNER --> REP
    RUNNER --> RSTORE

    T_BASE --> T_IE & T_STOCK & T_DEDUP & T_GEN

    REG --> GATE
    GATE <-->|"cache hit / miss"| CACHE
    GATE --> CLIENT_F

    CLIENT_F --> OAI
    OAI --> PROMPT
    OAI --> PARSER
    OAI --> BATCH

    OAI -->|"REST / SSE"| DEEPSEEK & KIMI & GPT & OTHERS

    MET --> RSTORE
    REP --> RSTORE
    RSTORE --> DATA_DIR

    DATA_DIR --> O_CFG & O_RES & O_SUM & O_RPT

    CONFIGS -.->|"åŠ è½½"| REG & RUNNER & OAI
    DATASETS -.->|"è¯»å–"| RUNNER

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ·å¼åº”ç”¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    class CLI,DS,WF_YAML,REG_YAML input
    class RUNNER,WFL,REG,GATE,CACHE,MET,REP orch
    class T_BASE,T_IE,T_STOCK,T_DEDUP,T_GEN task
    class CLIENT_F,OAI,PROMPT,PARSER,BATCH model
    class RSTORE,DATA_DIR store
    class DEEPSEEK,KIMI,GPT,OTHERS api
    class O_CFG,O_RES,O_SUM,O_RPT output
```

## 2. æ‰§è¡Œæ—¶åºï¼ˆworkflow æ¨¡å¼ï¼‰

```mermaid
sequenceDiagram
  participant U as User/CLI
  participant R as Runner
  participant W as WorkflowSpec
  participant T as EvalTask step
  participant G as LLMGateway
  participant C as EvalCache
  participant M as ModelRegistry and llm_core
  participant S as RunStore
  participant A as API

  U->>R: python -m eval.cli.runner --workflow ...
  R->>W: load_workflow()
  R->>S: write_config(config.json)

  loop each sample
    loop each workflow step
      R->>T: build_prompt(sample, context)
      R->>G: call(model_id, task, sample_cache_id, messages)
      G->>C: get(cache_key)
      alt cache hit
        C-->>G: cached UnifiedCallResult
      else cache miss
        G->>M: create_client(model_id, params)
        M->>A: chat.completions.create(...)
        A-->>M: response
        M-->>G: LLMResponse
        G->>C: set(cache_key, result)
      end
      G-->>R: UnifiedCallResult
      R->>T: parse()/metrics()
      R->>S: append_result(step row)
    end
    R->>S: append_result(workflow_e2e row)
  end

  R->>R: aggregate_records()
  R->>S: write_summary(summary.csv)
  R->>S: generate_report(report.md)
```

## 3. å½“å‰å®ç°è¦ç‚¹ï¼ˆå®¡é˜…ç»“è®ºï¼‰

1. æ¶æ„åˆ†å±‚æ¸…æ™°ï¼š`runner` è´Ÿè´£ç¼–æ’ï¼Œ`gateway` è´Ÿè´£è°ƒç”¨ä¸ç¼“å­˜ï¼Œ`registry` è´Ÿè´£æ¨¡å‹é…ç½®è§£æï¼Œ`store/report` è´Ÿè´£äº§ç‰©è½ç›˜ä¸å±•ç¤ºã€‚
2. æ•°æ®é—­ç¯å®Œæ•´ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä¼šäº§å‡º `config/results/summary/report`ï¼Œæ»¡è¶³æœ€å°å¯å¤ç°è¦æ±‚ã€‚
3. workflow ä¾èµ–å…³ç³»é€šè¿‡ `input_from` + ä¸Šæ¸¸ `parse_success` æ§åˆ¶ï¼Œå¤±è´¥ä¼šå†™å…¥ `skipped` è®°å½•å¹¶ç»§ç»­æ‰§è¡Œåç»­æ ·æœ¬ã€‚
4. å½“å‰å¹¶å‘èƒ½åŠ›ï¼š
   - task æ¨¡å¼æ”¯æŒæŒ‰æ¨¡å‹å¹¶å‘ï¼ˆ`--concurrency`ï¼Œæ¨¡å‹çº§ semaphoreï¼‰ã€‚
   - workflow æ¨¡å¼æ”¯æŒæ ·æœ¬çº§å¹¶å‘ï¼ˆ`--workflow-concurrency`ï¼‰ï¼Œå•æ ·æœ¬å†… step ä»ä¿æŒé¡ºåºä¾èµ–ã€‚
5. ç¼“å­˜å‘½ä¸­ç²’åº¦åˆç†ï¼šé”®ç”± `model + params + messages + sample_cache_id` ç»„æˆï¼Œèƒ½è¦†ç›– task/workflow çš„é‡å¤è°ƒç”¨å¤ç”¨ã€‚
6. `LLMGateway` å·²å¯¹ç›¸åŒ `model_id + params_override` å¤ç”¨ clientï¼Œé™ä½é‡å¤å»ºè¿å¼€é”€ã€‚
7. è¿è¡Œäº§ç‰©å·²å¸¦ç‰ˆæœ¬å¥‘çº¦ï¼š`results.schema_version=result_row.v1`ã€`summary.schema_version=summary_row.v1`ï¼Œ`config.json` å« `scorer_version`ã€‚

## 4. å»ºè®®çš„ä¸‹ä¸€æ­¥æ¼”è¿›

1. å°† workflow å¹¶å‘ä»â€œæ ·æœ¬çº§â€æ‰©å±•åˆ°â€œDAG çº§â€ï¼ˆå¯å¹¶è¡Œçš„ step åˆ†æ”¯è°ƒåº¦ï¼‰ã€‚
2. ä¸º `results.jsonl`/`summary.csv` æä¾›æ­£å¼ JSON Schema æ–‡ä»¶ï¼Œå¹¶åœ¨ CI ä¸­åšå¥‘çº¦æ ¡éªŒã€‚
3. å¢åŠ è·¨ run åŸºçº¿å¯¹æ¯”æŠ¥å‘Šï¼ˆæŒ‰ `task + model + prompt_version + scorer_version`ï¼‰ã€‚
