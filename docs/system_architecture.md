# ç³»ç»Ÿæ¶æ„ï¼ˆå½“å‰å®ç°å®¡é˜…ç‰ˆï¼‰

æœ¬æ–‡æ¡£åŸºäºå½“å‰ä»£ç å®ç°ï¼ˆ`bench/` + `llm_core/`ï¼‰æ•´ç†ï¼Œä¸æ˜¯ç›®æ ‡æ€è®¾è®¡å›¾ã€‚

## 1. æ¶æ„æ€»è§ˆå›¾

```mermaid
flowchart TB
    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ·å¼å®šä¹‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    classDef input     fill:#EFF6FF,stroke:#3B82F6,stroke-width:2px,color:#1E3A5F,font-weight:bold
    classDef orch      fill:#F0FDF4,stroke:#22C55E,stroke-width:2px,color:#14532D,font-weight:bold
    classDef model     fill:#FFF7ED,stroke:#F97316,stroke-width:2px,color:#7C2D12,font-weight:bold
    classDef store     fill:#F5F3FF,stroke:#8B5CF6,stroke-width:2px,color:#3B0764,font-weight:bold
    classDef output    fill:#FFF1F2,stroke:#F43F5E,stroke-width:2px,color:#881337,font-weight:bold
    classDef task      fill:#ECFEFF,stroke:#06B6D4,stroke-width:2px,color:#164E63,font-weight:bold
    classDef api       fill:#FEFCE8,stroke:#EAB308,stroke-width:2px,color:#713F12,font-weight:bold

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¾“å…¥å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph INPUT["  ğŸ“¥ INPUT â€” è¾“å…¥å±‚  "]
        direction LR
        CLI["ğŸ–¥ï¸ CLI Â· python -m bench.cli.runner"]
        DS["ğŸ“„ Dataset Â· *.jsonl"]
        WF_YAML["ğŸ“‹ Workflow Spec Â· news_pipeline.yaml"]
        REG_YAML["âš™ï¸ Model Registry Â· llm_providers.json (default)"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç¼–æ’å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph ORCH["  ğŸ›ï¸ ORCHESTRATOR â€” ç¼–æ’å±‚ (bench/)  "]
        direction TB
        RUNNER["ğŸƒ Runner Â· cli/runner.py Â· å•ä»»åŠ¡ / workflow å…¥å£"]
        WFL["ğŸ”€ WorkflowLoader Â· workflow.py Â· step ä¾èµ– & input_from"]
        REG["ğŸ“¦ ModelRegistry Â· registry.py Â· æ¨¡å‹æ³¨å†Œ + æˆæœ¬ä¼°ç®—"]
        GATE["ğŸšª LLMGateway Â· execution/gateway.py Â· ç»Ÿä¸€è°ƒç”¨é—¨é¢"]
        CACHE["ğŸ’¾ EvalCache Â· io/cache.py Â· model+params+messages é”®"]
        MET["ğŸ“Š Metrics Â· metrics/aggregate.py Â· aggregate_records()"]
        REP["ğŸ“ Reporter Â· reporting/reporter.py Â· MarkdownReporter"]
        ERR["ğŸ§­ Error Taxonomy Â· contracts/exceptions.py Â· ç»“æ„åŒ–é”™è¯¯å…ƒæ•°æ®"]

        subgraph TASKS["  ä»»åŠ¡æ’ä»¶å±‚ (bench/tasks/)  "]
            direction LR
            T_BASE["ğŸ”§ EvalTask Â· base.py Â· æŠ½è±¡åŸºç±»"]
            T_IE["ğŸ“Œ Task YAML Â· ie_json.yaml"]
            T_STOCK["ğŸ“ˆ Task YAML Â· stock_score.yaml"]
            T_DEDUP["ğŸ—ï¸ Task YAML Â· news_dedup.yaml"]
            T_GEN["âš¡ GenericTask Â· generic.py"]
        end
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¨¡å‹å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph MODEL["  ğŸ¤– MODEL LAYER â€” æ¨¡å‹å±‚ (llm_core/)  "]
        direction TB
        CLIENT_F["ğŸ­ LLM Client Factory Â· base_client.py"]
        OAI["ğŸ”Œ OpenAICompatibleClient Â· openai_client.py"]
        PROMPT["âœï¸ PromptRenderer Â· prompt_renderer.py Â· Jinja2 æ¸²æŸ“"]
        PARSER["ğŸ” ResponseParser Â· response_parser.py"]
        BATCH["âš™ï¸ BatchHelper Â· batch.py"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å­˜å‚¨å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph STORE_L["  ğŸ—„ï¸ STORE â€” å­˜å‚¨å±‚ (bench/)  "]
        direction LR
        RSTORE["ğŸ“ RunStore Â· io/store.py Â· äº§ç‰©è¯»å†™æŠ½è±¡"]
        DATA_DIR["ğŸ“‚ runs/{timestamp}/"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤–éƒ¨ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph APIS["  ğŸŒ å¤–éƒ¨ LLM API  "]
        direction LR
        DEEPSEEK["DeepSeek Â· API"]
        KIMI["Kimi Â· æœˆä¹‹æš—é¢"]
        GPT["OpenAI Â· gpt-4o etc."]
        OTHERS["å…¶ä»– Â· OpenAI-Compatible"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¾“å‡ºäº§ç‰© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph OUTPUT["  ğŸ“¤ OUTPUT â€” è¾“å‡ºäº§ç‰©  "]
        direction LR
        O_CFG["ğŸ“„ config.json Â· è¿è¡Œé…ç½®å¿«ç…§"]
        O_META["ğŸ§¾ run_meta.json Â· è¿è¡Œå…ƒä¿¡æ¯"]
        O_DFP["ğŸ§¬ dataset_fingerprint.json Â· æ•°æ®é›†æŒ‡çº¹"]
        O_MSNAP["ğŸ¤– model_snapshot.json Â· æ¨¡å‹å‚æ•°å¿«ç…§(è„±æ•)"]
        O_RES["ğŸ“Š results.jsonl Â· é€æ¡ç»“æœ v1"]
        O_SUM["ğŸ“‹ summary.csv Â· èšåˆç»Ÿè®¡ v1"]
        O_RPT["ğŸ“ report.md Â· å¯è¯»æŠ¥å‘Š"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é…ç½®æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph CONFIGS["  ğŸ“ CONFIGS  "]
        direction LR
        C_PROV["llm_providers.yaml Â· /json"]
        C_PROMPT["prompts/ Â· *.yaml"]
        C_ENV[".env Â· API Keys"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®é›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph DATASETS["  ğŸ“‚ DATASETS  "]
        direction LR
        D_BENCH["benchmark_news Â· .jsonl"]
        D_DEMO["demo_news Â· .jsonl"]
        D_EVAL["news_summary_eval Â· .jsonl"]
    end

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¿æ¥å…³ç³» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    CLI --> RUNNER
    DS --> RUNNER
    WF_YAML --> WFL --> RUNNER
    REG_YAML --> REG

    RUNNER --> TASKS
    RUNNER --> GATE
    RUNNER --> MET
    RUNNER --> REP
    RUNNER --> RSTORE
    RUNNER --> ERR

    T_BASE --> T_IE & T_STOCK & T_DEDUP & T_GEN

    REG --> GATE
    GATE <-->|"cache hit / miss"| CACHE
    GATE --> CLIENT_F

    CLIENT_F --> OAI
    OAI --> PROMPT
    OAI --> PARSER
    OAI --> BATCH

    OAI -->|"REST / SSE"| DEEPSEEK & KIMI & GPT & OTHERS

    MET --> RSTORE
    REP --> RSTORE
    RSTORE --> DATA_DIR

    DATA_DIR --> O_CFG & O_META & O_DFP & O_MSNAP & O_RES & O_SUM & O_RPT

    CONFIGS -.->|"åŠ è½½"| REG & RUNNER & OAI
    DATASETS -.->|"è¯»å–"| RUNNER

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ·å¼åº”ç”¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    class CLI,DS,WF_YAML,REG_YAML input
    class RUNNER,WFL,REG,GATE,CACHE,MET,REP orch
    class T_BASE,T_IE,T_STOCK,T_DEDUP,T_GEN task
    class CLIENT_F,OAI,PROMPT,PARSER,BATCH model
    class RSTORE,DATA_DIR store
    class DEEPSEEK,KIMI,GPT,OTHERS api
    class O_CFG,O_META,O_DFP,O_MSNAP,O_RES,O_SUM,O_RPT output
```

## 2. æ‰§è¡Œæ—¶åºï¼ˆworkflow æ¨¡å¼ï¼‰

```mermaid
sequenceDiagram
  participant U as User/CLI
  participant R as Runner
  participant W as WorkflowSpec
  participant T as EvalTask step
  participant G as LLMGateway
  participant C as EvalCache
  participant M as ModelRegistry and llm_core
  participant S as RunStore
  participant A as API

  U->>R: python -m bench.cli.runner --workflow ...
  R->>W: load_workflow()
  R->>S: write_config(config.json)
  R->>S: write_run_meta(run_meta.json)
  R->>S: write_dataset_fingerprint(dataset_fingerprint.json)
  R->>S: write_model_snapshot(model_snapshot.json)

  loop each sample
    loop each workflow step
      R->>T: build_prompt(sample, context)
      R->>G: call(model_id, task, sample_cache_id, messages)
      G->>C: get(cache_key)
      alt cache hit
        C-->>G: cached UnifiedCallResult
      else cache miss
        G->>M: create_client(model_id, params)
        M->>A: chat.completions.create(...)
        A-->>M: response
        M-->>G: LLMResponse
        G->>C: set(cache_key, result)
      end
      G-->>R: UnifiedCallResult
      R->>T: parse()/metrics()
      R->>S: append_result(step row)
    end
    R->>S: append_result(workflow_e2e row)
  end

  Note over R: workflow å¹¶å‘é‡‡ç”¨æµå¼å›æ”¶(FIRST_COMPLETED) Â· é¿å…å…¨é‡ gather å¸¦æ¥çš„å†…å­˜å³°å€¼
  R->>R: aggregate_records()
  R->>S: write_summary(summary.csv)
  R->>S: generate_report(report.md)
```

## 3. å½“å‰å®ç°è¦ç‚¹ï¼ˆå®¡é˜…ç»“è®ºï¼‰

1. æ¶æ„åˆ†å±‚æ¸…æ™°ï¼š`cli/runner` è´Ÿè´£ç¼–æ’ï¼Œ`execution/gateway` è´Ÿè´£è°ƒç”¨ä¸ç¼“å­˜ï¼Œ`registry` è´Ÿè´£æ¨¡å‹é…ç½®è§£æï¼Œ`io/store + reporting` è´Ÿè´£äº§ç‰©è½ç›˜ä¸å±•ç¤ºã€‚
2. æ•°æ®é—­ç¯å®Œæ•´ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä¼šäº§å‡º `config + run_meta + dataset_fingerprint + model_snapshot + results + summary + report`ã€‚
3. workflow ä¾èµ–å…³ç³»é€šè¿‡ `input_from` + ä¸Šæ¸¸ `parse_success` æ§åˆ¶ï¼Œå¤±è´¥ä¼šå†™å…¥ `skipped` è®°å½•å¹¶ç»§ç»­æ‰§è¡Œåç»­æ ·æœ¬ã€‚
4. å½“å‰å¹¶å‘èƒ½åŠ›ï¼š
   - task æ¨¡å¼æ”¯æŒæŒ‰æ¨¡å‹å¹¶å‘ï¼ˆ`--concurrency`ï¼Œæ¨¡å‹çº§ semaphoreï¼‰ã€‚
   - workflow æ¨¡å¼æ”¯æŒæ ·æœ¬çº§å¹¶å‘ï¼ˆ`--workflow-concurrency`ï¼‰ï¼Œå•æ ·æœ¬å†… step ä»ä¿æŒé¡ºåºä¾èµ–ï¼Œä¸”é‡‡ç”¨æµå¼å›æ”¶é¿å…å…¨é‡ `gather` çš„ OOM é£é™©ã€‚
5. ç¼“å­˜å‘½ä¸­ç²’åº¦åˆç†ï¼šé”®ç”± `model + params + messages + sample_cache_id` ç»„æˆï¼Œèƒ½è¦†ç›– task/workflow çš„é‡å¤è°ƒç”¨å¤ç”¨ã€‚
6. `LLMGateway` å·²å¯¹ç›¸åŒ `model_id + params_override` å¤ç”¨ clientï¼Œé™ä½é‡å¤å»ºè¿å¼€é”€ï¼›é‡è¯•é€€é¿å¼•å…¥ jitterï¼Œç¼“è§£é™æµæƒŠç¾¤ã€‚
7. é”™è¯¯å¤„ç†é‡‡ç”¨ç»“æ„åŒ–å¼‚å¸¸ä¸é”™è¯¯å…ƒæ•°æ®ï¼ˆ`error_type/error_stage/error_code`ï¼‰ï¼ŒæŠ¥å‘Šå¯æŒ‰é”™è¯¯ç±»å‹èšåˆã€‚
8. è¿è¡Œäº§ç‰©å·²å¸¦ç‰ˆæœ¬å¥‘çº¦ï¼š`results.schema_version=result_row.v1`ã€`summary.schema_version=summary_row.v1`ï¼Œå¹¶åœ¨ `run_meta.json` ä¸­è®°å½•è¿è¡Œç¯å¢ƒä¸ç‰ˆæœ¬å­—æ®µã€‚
9. ä»»åŠ¡æ”¯æŒ `default_params`ï¼ˆå¦‚ `response_format: {type: json_object}`ï¼‰å¹¶é€ä¼ åˆ°æ¨¡å‹è°ƒç”¨ã€‚

## 4. å»ºè®®çš„ä¸‹ä¸€æ­¥æ¼”è¿›

1. å°† workflow å¹¶å‘ä»â€œæ ·æœ¬çº§â€æ‰©å±•åˆ°â€œDAG çº§â€ï¼ˆå¯å¹¶è¡Œçš„ step åˆ†æ”¯è°ƒåº¦ï¼‰ã€‚
2. ä¸º `results.jsonl`/`summary.csv` æä¾›æ­£å¼ JSON Schema æ–‡ä»¶ï¼Œå¹¶åœ¨ CI ä¸­åšå¥‘çº¦æ ¡éªŒã€‚
3. å¢åŠ è·¨ run åŸºçº¿å¯¹æ¯”æŠ¥å‘Šï¼ˆæŒ‰ `task + model + prompt_version + scorer_version`ï¼‰ã€‚
